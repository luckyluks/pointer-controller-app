# Computer Pointer Controller

This app allows to control the computer mouse pointer to move according to the gaze of a person (either based on a video or camera stream).
Therefore, this project is build with the inference engine of the Intel OpenVINO™ toolkit [asd](assssd) for vision based deep learning models.
This project demonstrates the ability of creating a data pipeline that can handle multiple data sources and inference with multiple models in sequence.

| Details            |              |
|-----------------------|---------------|
| Language: |  Python 3.6.X |
| OpenVINO ToolKit: | 2020.1.023 |
| Hardware Used: | Intel(R) Core(TM) i5-6300U |
| Device (OpenVINO) Used: | CPU |

## How it works
This project builds on the inference engine of the [Intel OpenVINO™ toolkit] (https://docs.openvinotoolkit.org/).

As input for the app, the user can specify a data source (camera stream, video file or image).  
OpenCV is used for handling this user data in a data pipline, as presented in the following flow chart:

![data_pipeline](/bin/readme_data_pipeline.png)

The gaze estimation model (in this project: [gaze-estimation-adas-0002](https://docs.openvinotoolkit.org/latest/omz_models_intel_gaze_estimation_adas_0002_description_gaze_estimation_adas_0002.html)) requires **three** inputs (head pose, left eye image, right eye image) and is therefore supported by **three** other OpenVINO models in this project.
1. **Face detection model**: to detect the face of a person in the data  
and allows to crop the frame to a face frame.  
Used model in this project: [
face-detection-adas-binary-0001](https://docs.openvinotoolkit.org/latest/omz_models_intel_face_detection_adas_binary_0001_description_face_detection_adas_binary_0001.html)
2. **Pose estimation model**: to estimate the head pose (defined by yaw, pitch and roll).  
Used model in this project: [
head-pose-estimation-adas-0001](https://docs.openvinotoolkit.org/latest/omz_models_intel_head_pose_estimation_adas_0001_description_head_pose_estimation_adas_0001.html)
2. **Landmarks detection model**: to detect facial landmarks (eyes, mouth, nose)  
to allow the crop of the face frame to an eye frame per side.  
Used model in this project: [landmarks-regression-retail-0009](https://docs.openvinotoolkit.org/latest/omz_models_intel_landmarks_regression_retail_0009_description_landmarks_regression_retail_0009.html)


## Project Set Up and Installation

### Directory Structure
Generated with ```tree && du -sh``` the directory structure is the following:
```
.
├── README.md
├── bin
│   ├── demo.mp4
│   ├── demo_image.png
│   └── readme_data_pipeline.png
├── download_models.sh
├── main.py
├── models
│   └── [...] autogenerated with "download_models.sh"
|
├── requirements.txt
└── src
    ├── input_feeder.py
    ├── model_classes
    │   ├── facedetection_model.py
    │   ├── gazeestimation_model.py
    │   ├── landmarksdetection_model.py
    │   ├── model.py
    │   └── poseestimation_model.py
    └── mouse_controller.py
```

### Installation Instructions

To run this project the following setup must be completed (tested on Ubuntu 16.04):

1. **Install OpenVINO**: this depends on your distribution (Linux, Windows or Mac). A detailled installation instruction can be found at the [OpenVINO documentation](https://docs.openvinotoolkit.org/latest/install_directly.html).  A short walkthrough for Linux is given now:
    - Download the OpenVINO installer. For this project release 2020.01 was used. Find the installer download [here](https://software.intel.com/en-us/openvino-toolkit/choose-download).
        ```
        wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023_online.tgz
        ```
    - unpack the downloaded archive and change into the directory
        ```
        tar -xvf l_openvino_toolkit_p_2020.1.023_online.tgz
        cd l_openvino_toolkit_p_2020.1.023_online
        ```
    - Either execute the GUI or shell installer. The installer prints available options/problems in GUI/shell.
        ```
        sudo ./install.sh
        ```
    - Install external software dependencies (suggested by Intel)
        ```
        sudo -E /opt/intel/openvino/install_dependencies/install_openvino_dependencies.sh
        ```
    - Source the environments variables (everytime before using OpenVINO) or add the source to ```~/.bashrc``` to automatically load the variables at shell start-up.
        ```
        source /opt/intel/openvino/bin/setupvars.sh
        ```
2. **Check system dependencies**: *WARNING:* can vary dependend on the system!
    - Install python3 pip and virtual environment functions:
        ```
        sudo apt update
        sudo apt-get install python3-pip python3-venv
        ```
3. **Setup virtual environment**: use python virtual environment to encapsulate packages
    - Create the virtual environment *openvino-venv*
        ```
        python3 -m venv openvino-env
        ```
    - Add the openvino variables setup to virtual environment. Therefore, open the environment file with a text editor, e.g. ```nano openvino-venv/bin/activate``` . Then add the following line to the end of the file and save it:
        ```
        source /opt/intel/openvino/bin/setupvars.sh
        ```
    - Activate the environment:
        ```
        source openvino-env/bin/activate
        ```
4. **Setup project files**: download the project files
    - clone the repo in the user home directory and change into the project directory
        ```
        cd ~
        git clone https://github.com/luckyluks/pointer-controller-app.git
        cd pointer-controller-app
        ```
    - Install pip dependencies
        ```
        python3 -m pip install -r requirements.txt
        ```
    - Download the required model. Optionally other models could be used and replace them.  
      Use the ```--all_available_precisions``` flag to download all available precisions!
        ```
        ./download_models.sh --all_available_precisions
        ```
        This creates a new directory ```models/``` and downloads the models (face-detection-adas-binary-0001, head-pose-estimation-adas-0001, landmarks-regression-retail-0009, gaze-estimation-adas-0002) in all available precisions into this new directory using the OpenVINO model downloader.

## Usage

### Command Line Arguments
The integrated argument parser returns a description of the available command line arguments.  
You can see them with ```python3 main.py --help``` 

**TODO**
```
asdasdasdasd 
```

### Basic Run on Camera or Video or Image
- A basic example to run the application on a camera stream is:
    ```
    python3 main.py \
    --model_face_detection models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml \
    --model_pose_estimation models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml \
    --model_landmarks_detection models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml \
    --model_gaze_estimation models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml --input cam \
    --output bin/cam_output.mp4 \
    --draw_prediction \
    --debug
    ```
- A basic example to run the application on a video file is:
    ```
    python3 main.py \
    --model_face_detection models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml \
    --model_pose_estimation models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml \
    --model_landmarks_detection models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml \
    --model_gaze_estimation models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml --input bin/demo_video.mp4 \
    --output bin/demo_video_output.mp4 \
    --draw_prediction \
    --debug
    ```
- A basic example to run the application on a image file is:
    ```
    python3 main.py \
    --model_face_detection models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml \
    --model_pose_estimation models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml \
    --model_landmarks_detection models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml \
    --model_gaze_estimation models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml --input bin/demo_image.png \
    --output bin/demo_image_out.png \
    --draw_prediction \
    --debug
    ```


## Benchmarks
*TODO:* Include the benchmark results of running your model on multiple hardwares and multiple model precisions. Your benchmarks can include: model loading time, input/output processing time, model inference time etc.

## Results
*TODO:* Discuss the benchmark results and explain why you are getting the results you are getting. For instance, explain why there is difference in inference time for FP32, FP16 and INT8 models.

## Stand Out Suggestions
This is where you can provide information about the stand out suggestions that you have attempted.

### Async Inference
If you have used Async Inference in your code, benchmark the results and explain its effects on power and performance of your project.

### Edge Cases
There will be certain situations that will break your inference flow. For instance, lighting changes or multiple people in the frame. Explain some of the edge cases you encountered in your project and how you solved them to make your project more robust...
